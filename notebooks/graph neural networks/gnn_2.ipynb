{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from itertools import product\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/cleaned/cleaned_vessel_calls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataframe\n",
    "df[\"arrivalDate\"] = pd.to_datetime(df[\"arrivalDate\"])\n",
    "df[\"sailingDate\"] = pd.to_datetime(df[\"sailingDate\"])\n",
    "df[\"duration\"] = (df[\"sailingDate\"] - df[\"arrivalDate\"]) / pd.Timedelta(days=1)\n",
    "df[\"month\"] = df[\"arrivalDate\"].dt.month\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and filter data\n",
    "df.sort_values(by=[\"IMO\", \"arrivalDate\"], inplace=True)\n",
    "df['next_unlocode'] = df.groupby('IMO')['place.unlocode'].shift(-1)\n",
    "df['is_last_imo'] = df['IMO'] != df['IMO'].shift(-1)\n",
    "df = df[~df[\"is_last_imo\"]]\n",
    "df = df[df[\"Event_Type\"] != \"ARRIVAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"is_last_imo\", \"Event_Type\", \"Timestamp\", \"vessel.vesselName\", \"IMO\", \"arrivalDate\", \"sailingDate\"])\n",
    "\n",
    "# Rename columns for consistency\n",
    "df = df.rename(columns={'place.unlocode': 'current_unlocode', 'place.placeName': 'port_name', 'vessel.vesselType': 'vessel_type', 'place.placeType': 'place_type', 'place.countryName': 'country_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_name</th>\n",
       "      <th>current_unlocode</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country_name</th>\n",
       "      <th>vessel_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>month</th>\n",
       "      <th>next_unlocode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314761</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>USLAX</td>\n",
       "      <td>Port</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Vessel Type (unspecified)</td>\n",
       "      <td>7.579803</td>\n",
       "      <td>1</td>\n",
       "      <td>CNJGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314763</th>\n",
       "      <td>Jiangyin</td>\n",
       "      <td>CNJGY</td>\n",
       "      <td>Port</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>Vessel Type (unspecified)</td>\n",
       "      <td>1.484931</td>\n",
       "      <td>2</td>\n",
       "      <td>CNTXG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314765</th>\n",
       "      <td>Tianjin Xingang Port</td>\n",
       "      <td>CNTXG</td>\n",
       "      <td>Port</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>Vessel Type (unspecified)</td>\n",
       "      <td>0.854514</td>\n",
       "      <td>3</td>\n",
       "      <td>CNQAW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314767</th>\n",
       "      <td>Qianwan</td>\n",
       "      <td>CNQAW</td>\n",
       "      <td>Sub Port</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>Vessel Type (unspecified)</td>\n",
       "      <td>0.613380</td>\n",
       "      <td>3</td>\n",
       "      <td>CNMSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314769</th>\n",
       "      <td>Meishan</td>\n",
       "      <td>CNMSN</td>\n",
       "      <td>Sub Port</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>Vessel Type (unspecified)</td>\n",
       "      <td>1.021157</td>\n",
       "      <td>3</td>\n",
       "      <td>CNNSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>Port Klang (Pelabuhan Klang)</td>\n",
       "      <td>MYPKG</td>\n",
       "      <td>Port</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>fully cellular containership</td>\n",
       "      <td>0.871701</td>\n",
       "      <td>9</td>\n",
       "      <td>INMAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571</th>\n",
       "      <td>Chennai (ex Madras)</td>\n",
       "      <td>INMAA</td>\n",
       "      <td>Port</td>\n",
       "      <td>India</td>\n",
       "      <td>fully cellular containership</td>\n",
       "      <td>1.138021</td>\n",
       "      <td>9</td>\n",
       "      <td>BDCGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12573</th>\n",
       "      <td>Chittagong (Chattogram)</td>\n",
       "      <td>BDCGP</td>\n",
       "      <td>Port</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>fully cellular containership</td>\n",
       "      <td>1.997604</td>\n",
       "      <td>9</td>\n",
       "      <td>THLCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12575</th>\n",
       "      <td>Laem Chabang</td>\n",
       "      <td>THLCH</td>\n",
       "      <td>Port</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>fully cellular containership</td>\n",
       "      <td>0.713912</td>\n",
       "      <td>9</td>\n",
       "      <td>SGSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12577</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>SGSIN</td>\n",
       "      <td>Port</td>\n",
       "      <td>Republic of Singapore</td>\n",
       "      <td>fully cellular containership</td>\n",
       "      <td>0.272824</td>\n",
       "      <td>9</td>\n",
       "      <td>MYPKG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170752 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           port_name current_unlocode place_type  \\\n",
       "314761                   Los Angeles            USLAX       Port   \n",
       "314763                      Jiangyin            CNJGY       Port   \n",
       "314765          Tianjin Xingang Port            CNTXG       Port   \n",
       "314767                       Qianwan            CNQAW   Sub Port   \n",
       "314769                       Meishan            CNMSN   Sub Port   \n",
       "...                              ...              ...        ...   \n",
       "12569   Port Klang (Pelabuhan Klang)            MYPKG       Port   \n",
       "12571            Chennai (ex Madras)            INMAA       Port   \n",
       "12573        Chittagong (Chattogram)            BDCGP       Port   \n",
       "12575                   Laem Chabang            THLCH       Port   \n",
       "12577                      Singapore            SGSIN       Port   \n",
       "\n",
       "                      country_name                   vessel_type  duration  \\\n",
       "314761    United States of America     Vessel Type (unspecified)  7.579803   \n",
       "314763  People's Republic of China     Vessel Type (unspecified)  1.484931   \n",
       "314765  People's Republic of China     Vessel Type (unspecified)  0.854514   \n",
       "314767  People's Republic of China     Vessel Type (unspecified)  0.613380   \n",
       "314769  People's Republic of China     Vessel Type (unspecified)  1.021157   \n",
       "...                            ...                           ...       ...   \n",
       "12569                     Malaysia  fully cellular containership  0.871701   \n",
       "12571                        India  fully cellular containership  1.138021   \n",
       "12573                   Bangladesh  fully cellular containership  1.997604   \n",
       "12575                     Thailand  fully cellular containership  0.713912   \n",
       "12577        Republic of Singapore  fully cellular containership  0.272824   \n",
       "\n",
       "        month next_unlocode  \n",
       "314761      1         CNJGY  \n",
       "314763      2         CNTXG  \n",
       "314765      3         CNQAW  \n",
       "314767      3         CNMSN  \n",
       "314769      3         CNNSA  \n",
       "...       ...           ...  \n",
       "12569       9         INMAA  \n",
       "12571       9         BDCGP  \n",
       "12573       9         THLCH  \n",
       "12575       9         SGSIN  \n",
       "12577       9         MYPKG  \n",
       "\n",
       "[170752 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in ['port_name', 'place_type', 'country_name', 'vessel_type']:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ports = pd.concat([df['current_unlocode'], df['next_unlocode']])\n",
    "\n",
    "# Create unique identifiers for each port\n",
    "unique_ports = all_ports.unique()\n",
    "port_to_id = {port: i for i, port in enumerate(unique_ports)}\n",
    "\n",
    "df['current_unlocode'] = df['current_unlocode'].map(port_to_id)\n",
    "df['next_unlocode'] = df['next_unlocode'].map(port_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "G = nx.from_pandas_edgelist(df, 'current_unlocode', 'next_unlocode', edge_attr=True)\n",
    "\n",
    "# Initialize all nodes with default attributes\n",
    "default_attrs = {\n",
    "    'port_name': 0,\n",
    "    'place_type': 0,\n",
    "    'country_name': 0,\n",
    "    'vessel_type': 0,\n",
    "    'duration': 0.0,\n",
    "    'month': 0\n",
    "}\n",
    "\n",
    "for node in G.nodes:\n",
    "    G.nodes[node].update(default_attrs)\n",
    "\n",
    "# Add node features (example: duration and month)\n",
    "for index, row in df.iterrows():\n",
    "    G.nodes[row['current_unlocode']]['port_name'] = row['port_name']\n",
    "    G.nodes[row['current_unlocode']]['place_type'] = row['place_type']\n",
    "    G.nodes[row['current_unlocode']]['country_name'] = row['country_name']\n",
    "    G.nodes[row['current_unlocode']]['vessel_type'] = row['vessel_type']\n",
    "    G.nodes[row['current_unlocode']]['duration'] = row['duration']\n",
    "    G.nodes[row['current_unlocode']]['month'] = row['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attrs = []\n",
    "for node in G.nodes(data=True):\n",
    "    node_attrs.append([node[1][attr] for attr in default_attrs.keys()])\n",
    "\n",
    "node_attrs = np.array(node_attrs, dtype=np.float32)\n",
    "scaler = MinMaxScaler()\n",
    "node_attrs = scaler.fit_transform(node_attrs)\n",
    "\n",
    "# Update graph with normalized attributes\n",
    "for i, node in enumerate(G.nodes):\n",
    "    for j, attr in enumerate(default_attrs.keys()):\n",
    "        G.nodes[node][attr] = node_attrs[i, j]\n",
    "\n",
    "# Convert to PyTorch Geometric data\n",
    "data = from_networkx(G)\n",
    "\n",
    "# Ensure features are tensors\n",
    "data.x = torch.tensor([list(node[1].values()) for node in G.nodes(data=True)], dtype=torch.float)\n",
    "\n",
    "# Set target variable y\n",
    "node_to_index = {node: i for i, node in enumerate(G.nodes)}\n",
    "data.y = torch.zeros(len(G.nodes), dtype=torch.long)\n",
    "for index, row in df.iterrows():\n",
    "    node_index = node_to_index[row['current_unlocode']]\n",
    "    data.y[node_index] = row['next_unlocode']\n",
    "\n",
    "# Ensure the target values are within the valid range\n",
    "num_classes = len(np.unique(data.y.numpy()))\n",
    "data.y = torch.clamp(data.y, max=num_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test masks\n",
    "num_nodes = data.num_nodes\n",
    "indices = np.arange(num_nodes)\n",
    "np.random.shuffle(indices)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "split = int(0.8 * num_nodes)\n",
    "train_mask[indices[:split]] = True\n",
    "test_mask[indices[split:]] = True\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: (16, 0.2, 0.001), Best Accuracy: 0.2949438202247191\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader), correct \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mint\u001b[39m(data\u001b[38;5;241m.\u001b[39mtest_mask\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test()\n\u001b[0;32m    144\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[12], line 114\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    113\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[0;32m    115\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    116\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the enhanced GNN model with GAT\n",
    "class EnhancedGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, hidden_dim, dropout):\n",
    "        super(EnhancedGNN, self).__init__()\n",
    "        self.gcn1 = GCNConv(num_node_features, hidden_dim)\n",
    "        self.gat1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=True, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=False, dropout=dropout)\n",
    "        self.fc = Linear(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Function to perform hyperparameter tuning\n",
    "def hyperparameter_tuning(params, data, num_classes):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for hidden_dim, dropout, learning_rate in product(*params.values()):\n",
    "        model = EnhancedGNN(data.x.shape[1], num_classes, hidden_dim, dropout)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        train_loader = DataLoader([data], batch_size=1, shuffle=True)\n",
    "\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "\n",
    "        def train():\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                pred = out[data.train_mask].max(dim=1)[1]\n",
    "                correct += pred.eq(data.y[data.train_mask]).sum().item()\n",
    "                \n",
    "            return total_loss / len(train_loader), correct / int(data.train_mask.sum())\n",
    "\n",
    "        def test():\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for data in train_loader:\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                pred = out[data.test_mask].max(dim=1)[1]\n",
    "                correct += pred.eq(data.y[data.test_mask]).sum().item()\n",
    "                \n",
    "            return total_loss / len(train_loader), correct / int(data.test_mask.sum())\n",
    "\n",
    "        for epoch in range(200):\n",
    "            train_loss, train_acc = train()\n",
    "            test_loss, test_acc = test()\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracies.append(test_acc)\n",
    "\n",
    "        if test_accuracies[-1] > best_accuracy:\n",
    "            best_accuracy = test_accuracies[-1]\n",
    "            best_params = (hidden_dim, dropout, learning_rate)\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Example usage:\n",
    "params = {\n",
    "    'hidden_dim': [16, 32, 64],\n",
    "    'dropout': [0.2, 0.4, 0.6],\n",
    "    'learning_rate': [0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Assuming `data` and `num_classes` are already defined\n",
    "num_classes = len(np.unique(df['next_unlocode']))\n",
    "best_params, best_accuracy = hyperparameter_tuning(params, data, num_classes)\n",
    "print(f\"Best Parameters: {best_params}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Now use the best parameters to train the final model\n",
    "hidden_dim, dropout, learning_rate = best_params\n",
    "model = EnhancedGNN(data.x.shape[1], num_classes, hidden_dim, dropout)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Proceed with training the final model using the best hyperparameters\n",
    "\n",
    "# Training and testing loops with plotting\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred = out[data.train_mask].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y[data.train_mask]).sum().item()\n",
    "        \n",
    "    return total_loss / len(train_loader), correct / int(data.train_mask.sum())\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred = out[data.test_mask].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y[data.test_mask]).sum().item()\n",
    "        \n",
    "    return total_loss / len(train_loader), correct / int(data.test_mask.sum())\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_loss, train_acc = train()\n",
    "    test_loss, test_acc = test()\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training loss curve\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Testing/Training Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training accuracy curve\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Testing/Training Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lists to store training loss and accuracy, and test loss and accuracy\n",
    "# train_losses = []\n",
    "# train_accuracies = []\n",
    "# test_losses = []\n",
    "# test_accuracies = []\n",
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     for data in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(data)\n",
    "#         loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         pred = out[data.train_mask].max(dim=1)[1]\n",
    "#         correct += pred.eq(data.y[data.train_mask]).sum().item()\n",
    "        \n",
    "#     return total_loss / len(train_loader), correct / int(data.train_mask.sum())\n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     for data in train_loader:\n",
    "#         out = model(data)\n",
    "#         loss = F.nll_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         pred = out[data.test_mask].max(dim=1)[1]\n",
    "#         correct += pred.eq(data.y[data.test_mask]).sum().item()\n",
    "        \n",
    "#     return total_loss / len(train_loader), correct / int(data.test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(200):\n",
    "#     train_loss, train_acc = train()\n",
    "#     test_loss, test_acc = test()\n",
    "\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accuracies.append(train_acc)\n",
    "    \n",
    "#     test_losses.append(test_loss)\n",
    "#     test_accuracies.append(test_acc)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot learning curves\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Plot training loss curve\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(test_losses, label='Test Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Testing/Training Loss Curve')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot training accuracy curve\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.plot(train_accuracies, label='Training Accuracy')\n",
    "# plt.plot(test_accuracies, label='Test Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Testing/Training Accuracy Curve')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
